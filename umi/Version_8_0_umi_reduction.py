__author__ = 'ian'import syssys.modules[__name__].__dict__.clear()import numpy as npimport matplotlib.pyplot as pltimport ipdbfrom Bio.Seq import Seqfrom Bio import SeqIOfrom Bio import pairwise2from Bio.pairwise2 import format_alignmentfrom Bio.SeqRecord import SeqRecordimport time as timeimport datetimeimport os as osfrom Bio.Align.Applications import MuscleCommandlinefrom itertools import izip# import psutilimport randomimport asttoday = datetime.date.today()start_t = time.time()#fetches any fastq files in the directory!file_list = []# file_list.append('test_read.fastq')# file_list.append('elena_test.fastq')for file in os.listdir(os.getcwd()):    if file[-6:] == '.fastq':        file_list.append(os.getcwd()+'/'+file)super_directory = str(today) + 'distance_probe' + str(time.time())os.makedirs(super_directory)with open('umi_master_dicti', 'r') as myfile:    dicti=ast.literal_eval(myfile.read())with open('umi_master_dictii', 'r') as myfile:    dictii=ast.literal_eval(myfile.read())with open('umi_master_dictiii', 'r') as myfile:    dictiii=ast.literal_eval(myfile.read())with open('umi_master_dictiv', 'r') as myfile:    dictiv=ast.literal_eval(myfile.read())# ipdb.set_trace()with open('reference_sequence.txt', 'r') as myfile:    common_sequence=myfile.read().replace('\n', '')score_matrix = {            ('A','A'):4         ,('A','T'):-4   ,('A','C'):-4   ,('A','G'):-4   ,('A','N'):0   ,('A','S'):-4  ,('A','-'):0,            ('T', 'A'): -4      ,('T', 'T'): 4  ,('T', 'C'): -4 ,('T', 'G'): -4 ,('T','N'):0   ,('T','S'):-4  ,('T','-'):0,            ('C', 'A'): -4      ,('C', 'T'): -4 ,('C', 'C'): 4  ,('C', 'G'): -4 ,('C','N'):0   ,('C','S'):1   ,('C','-'):0,            ('G', 'A'): -4      ,('G', 'T'): -4 ,('G', 'C'): -4 ,('G', 'G'): 4  ,('G','N'):0   ,('G','S'):1   ,('G','-'):0,            ('N', 'A'): 0       ,('N', 'T'): 0  ,('N', 'C'): 0  ,('N', 'G'): 0  ,('N', 'N'):0  ,('N', 'S'): 0 ,('N', '-'): 0,            ('S', 'A'): -4      ,('S', 'T'): -4 ,('S', 'C'): 1  ,('S', 'G'): 1  ,('S', 'N'):0  ,('S', 'S'):1  ,('S', '-'): 0,            ('-', 'A'): 0       ,('-', 'T'): 0  ,('-', 'C'): 0  ,('-', 'G'): 0  ,('-', 'N'):0  ,('-', 'S'):0  ,('-', '-'): 0        }with open('left_barcodes.txt', 'r') as myfile:    left_sequences = ast.literal_eval(myfile.read())with open('right_barcodes.txt', 'r') as myfile:    right_sequences = ast.literal_eval(myfile.read())    # left_sequences=[myfile.read().replace('\n', ',')]# left_sequences = ['AACAGT','AGAGTC','CAGACT'] #rows in the matrix# right_sequences = ['CAGTTT','AGTCCT','GCCTAT','GTACGT'] #columns in the matrix# ipdb.set_trace()file_counter = 0#Here we establish threshold scores for the alignments of both the common region and the barcodescs_thresh = raw_input("Please enter reference sequence mismatch tolerance (btw 0 and 1) or leave blank (default = 0.4): ") or 0.5bc_thresh= raw_input("Please enter barcode mismatch tolerance (btw 0 and 1) or leave blank (default = 0.8) : ") or 0.6common_sequence_score_threshold = int(float(cs_thresh) * pairwise2.align.localds(common_sequence, common_sequence, score_matrix, -15, -1,penalize_end_gaps=False,one_alignment_only=True)[0][2])barcode_score_threshold = int(float(bc_thresh) * pairwise2.align.localds(left_sequences[0], left_sequences[0], score_matrix, -15, -1,penalize_end_gaps=False,one_alignment_only=True)[0][2])perform_alignment = raw_input("perform an alignment at the end of each grouping? (note - takes a long time for big files) ('y'/'n')") or 'n'pairwise_association_matrix_master = np.zeros((len(left_sequences), len(right_sequences)))umireduced_pairwise_association_matrix_master = np.zeros((len(left_sequences), len(right_sequences)))discard_association_matrix_master = np.zeros((len(left_sequences), len(right_sequences)))with open(super_directory + "/bc_pairs.fsa", "w") as aa, \        open(super_directory + "/discarded.fsa", "w", ) as bb, \        open(super_directory + "/full_discarded.fsa", "w", ) as cc, \        open(super_directory + "/full_accepted.fsa", "w", ) as dd, \        open(super_directory + "/all_flipped_reads.fsa", "w", ) as ee:    for file in file_list:        common_sequence_positions = []        accepted_cs_position = []        discarded_cs_position = []        empty_tally = 0        good_tally = 0        discard_tally = 0        full_tally = 0        discard_by_barcode_problem_tally = 0        counter = 0        file_counter += 1        directory_name = super_directory + '/' + str(file_counter)        os.makedirs(directory_name)        print file        pairwise_association_matrix = np.zeros((len(left_sequences), len(right_sequences)))        umireduced_pairwise_association_matrix = np.zeros((len(left_sequences), len(right_sequences)))        discard_association_matrix = np.zeros((len(left_sequences), len(right_sequences)))        discard_records = []        discard_records_temp = []        pair_records = []        pair_records_temp = []        average_iteration_time = 0        raw = SeqIO.parse(file, "fastq")        with open(directory_name +"/raw.fasta", "w") as output_handle:            SeqIO.write(raw, output_handle, "fasta")        with open(file[0:-6] + "UMIs", 'r') as myfile:            umi_catalog = ast.literal_eval(myfile.read())        with open(directory_name + "/bc_pairs.fsa", "w") as a, \                open(directory_name + "/discarded.fsa", "w",) as b, \                open(directory_name + "/full_discarded.fsa", "w",) as c,\                open(directory_name + "/full_accepted.fsa", "w", ) as d, \                open(directory_name + "/all_flipped_reads.fsa", "w", ) as e:            for seq_record in SeqIO.parse(file, "fastq"):                if umi_catalog[seq_record.id][1] == '-':                    inverse_weight = 1                elif umi_catalog[seq_record.id][1] == '4':                    inverse_weight = dictiv[umi_catalog[seq_record.id][3:9]]                elif umi_catalog[seq_record.id][1] == '3':                    inverse_weight = dictiii[umi_catalog[seq_record.id][3:9]]                elif umi_catalog[seq_record.id][1] == '2':                    inverse_weight = dictii[umi_catalog[seq_record.id][3:9]]                elif umi_catalog[seq_record.id][1] == '1':                    inverse_weight = dicti[umi_catalog[seq_record.id][3:9]]                else:                    print('error with umi assignment')                    ipdb.set_trace()                # print inverse_weight                full_tally += 1                iteration_start_t = time.time()                counter += 1                # print 'sequence ' + seq_record.id + ' length: ' + str(len(seq_record.seq))                #locate hybridization region by pw alignment with reference sequence                plus_strand_alignment = pairwise2.align.localds(common_sequence, seq_record.seq, score_matrix, -15, -1,penalize_end_gaps=False,one_alignment_only=True)                minus_strand_alignment = pairwise2.align.localds(common_sequence, seq_record.seq.reverse_complement(), score_matrix, -15, -1, penalize_end_gaps=False,one_alignment_only=True)                # plus_strand_score = plus_strand_alignment [2]                # minus_strand_score = minus_strand_alignment[2]                try:                    if max([i[2] for i in plus_strand_alignment]) > max([i[2] for i in minus_strand_alignment]):                        #then we have a plus strand                        main_sequence = seq_record.seq                        main_alignments = plus_strand_alignment                    elif max([i[2] for i in plus_strand_alignment]) < max([i[2] for i in minus_strand_alignment]):                        # then we have a minus strand                        main_sequence = seq_record.seq.reverse_complement()                        main_alignments = minus_strand_alignment                        # ipdb.set_trace()                    else:                        #then there is a tie, and this is strange                        if max([i[2] for i in plus_strand_alignment]) > common_sequence_score_threshold:                            print 'error - plus and minus strands have equal hybridization region scores of ' +str(max([i[2] for i in plus_strand_alignment]))                        main_sequence = seq_record.seq                        main_alignments = plus_strand_alignment                except:                    continue                #now we have a winning read that should be oriented correctly, if its scores isnt good though, we discard                flipped_read = main_alignments[0]                if flipped_read[2] < common_sequence_score_threshold:                    flipped_record_full = SeqRecord(main_sequence,                                                    id='flipped' + seq_record.id,                                                    name='flipped' + seq_record.id,                                                    description="flipped raw reads - both bad and good scoring")                    SeqIO.write(flipped_record_full, e, "fasta")                    discarded_cs_position += [flipped_read[3]+11]                    common_sequence_positions += [flipped_read[3] + 11]                    discard_record = SeqRecord(main_sequence[flipped_read[3]-6:flipped_read[4]+6],                                               id='_discard_bycommonsequence' + seq_record.id,                                               name='_discard_bycommonsequence' + seq_record.id,                                               description="no barcodes searched, common sequence alignment failed" )                    discard_record_full = SeqRecord(main_sequence,                                               id='_discard_bycommonsequence' + seq_record.id,                                               name='_discard_bycommonsequence' + seq_record.id,                                               description="no barcodes searched, common sequence alignment failed")                    discard_tally += 1                    if not discard_record.seq:                        empty_tally += 1                    else:                        SeqIO.write(discard_record, b, "fasta")                        SeqIO.write(discard_record, bb, "fasta")                        SeqIO.write(discard_record_full, c, "fasta")                        SeqIO.write(discard_record_full, cc, "fasta")                        # discard_records += [discard_record]                        if counter % 1000 == 0:                            # iteration_time = iteration_end_t - iteration_start_t                            # average_iteration_time = (average_iteration_time * counter - 1 + iteration_time) / counter                            print 'reads processed so far: ' + str(counter)                            # print average_iteration_time                            # process = psutil.Process(os.getpid())                            # print(process.memory_info().rss)                #the winning orientation has a high enough common sequence alignment score to permit barcode check                elif flipped_read[2] >= common_sequence_score_threshold:                    common_sequence_positions += [flipped_read[3]+11]                    flipped_record_full = SeqRecord(main_sequence,                                                    id='flipped' + seq_record.id,                                                    name='flipped' + seq_record.id,                                                    description="flipped raw reads - both bad and good scoring")                    SeqIO.write(flipped_record_full, e, "fasta")                    SeqIO.write(flipped_record_full, ee, "fasta")                    bc_1_extract=''                    bc_2_extract=''                    best_lscore = 0                    left_placeholder = 'no good candidate'                    discarded_l_placeholder = 'no current candidate for discard'                    randomized_range = range(0, len(left_sequences))                    random.shuffle(randomized_range)                    for l_tag in randomized_range:                        #check everything to the left of the read's midpoint for the left side barcode, selected apriori from the list                        try:                            # print 'success'                            bc_alignments = pairwise2.align.localds(left_sequences[l_tag], flipped_read[1][flipped_read[3]-7:flipped_read[3]+1], score_matrix, -15, -1, penalize_end_gaps=False, one_alignment_only=False)                        except:                            print 'error'                            bc_alignments = pairwise2.align.localds(left_sequences[l_tag], flipped_read[1][                                                                                           0:                                                                                           flipped_read[3] + 1],                                                                    score_matrix, -15, -1, penalize_end_gaps=False,                                                                    one_alignment_only=False)                        # ipdb.set_trace()                        for candidate_alignment in bc_alignments:                            score = candidate_alignment[2]                            #whatever we pulled out now, we check if it has an acceptable score, since we are checking all                            #the barcodes in the list, there are bound to be several bad ones. We go through all of them                            #and take the one with the highest score and also check that it is above a minimal threshold                            if score >= barcode_score_threshold and score > best_lscore:                                bc_1_extract = candidate_alignment                                left_placeholder = l_tag                                best_lscore = score                                discarded_best_l_candidate = candidate_alignment                                discarded_l_placeholder = l_tag                            elif score > best_lscore:                                best_lscore = score                                discarded_l_placeholder = l_tag                                discarded_best_l_candidate = candidate_alignment                            else:pass                                # discarded_l_placeholder = l_tag                                # discarded_best_l_candidate = candidate_alignment                    if discarded_l_placeholder == 'no current candidate for discard':                        discarded_l_placeholder = random.choice(range(0,len(left_sequences)))                    best_rscore = 0                    right_placeholder = 'no good candidate'                    discarded_r_placeholder = 'no current candidate for discard'                    #repeat the process now for the right hand side and the right hand barcode                    randomized_range = range(0,len(right_sequences))                    random.shuffle(randomized_range)                    for r_tag in randomized_range:                        try:                            # print 'success'                            bc_alignments = pairwise2.align.localds(right_sequences[r_tag], flipped_read[1][flipped_read[4]-1:flipped_read[4]+7], score_matrix, -15, -1, penalize_end_gaps=False, one_alignment_only=False)                        except:                            print 'error'                            bc_alignments = pairwise2.align.localds(right_sequences[r_tag], flipped_read[1][                                                                                            flipped_read[4] - 1:],                                                                    score_matrix, -15, -1, penalize_end_gaps=False,                                                                    one_alignment_only=False)                        for candidate_alignment in bc_alignments:                            score = candidate_alignment[2]                            if score >= barcode_score_threshold and score > best_rscore:                                bc_2_extract = candidate_alignment                                right_placeholder = r_tag                                best_rscore = score                                discarded_r_placeholder = r_tag                                discarded_best_r_candidate = candidate_alignment                            elif score > best_rscore:                                best_rscore = score                                discarded_r_placeholder = r_tag                                discarded_best_r_candidate = candidate_alignment                            else:pass                                # discarded_r_placeholder = r_tag                                # discarded_best_r_candidate = candidate_alignment                    if discarded_r_placeholder == 'no current candidate for discard':                        discarded_r_placeholder = random.choice(range(0,len(right_sequences)))                    if left_placeholder == 'no good candidate' or right_placeholder == 'no good candidate':                        # ipdb.set_trace()                        discard_association_matrix[discarded_l_placeholder, discarded_r_placeholder] += 1                        discard_association_matrix_master[discarded_l_placeholder, discarded_r_placeholder] += 1                        discarded_cs_position += [flipped_read[3]+11]                        #then we must discard this sequence!                        #Seq(flipped_read[1][flipped_read[3]-6:flipped_read[4]+6])                        # print seq_record.id                        discard_record = SeqRecord(main_sequence[flipped_read[3]-6:flipped_read[4]+6],                                                   id='discard_by_bardcode_mismatch'+seq_record.id,                                                   name='discard_by_bardcode_mismatch'+seq_record.id,                                                   description="closest candidates discovered: " + str(                                                       discarded_best_l_candidate[0]) + " with score of " + str(                                                       discarded_best_l_candidate[2]) + " and " + str(                                                       discarded_best_r_candidate[0]) + " with score of " + str(                                                       discarded_best_r_candidate[2]))                        discard_record_full = SeqRecord(main_sequence,                                                        id='discard_by_bardcode_mismatch' + seq_record.id,                                                        name='discard_by_bardcode_mismatch' + seq_record.id,                                                        description="closest candidates discovered: " + str(                                                            discarded_best_l_candidate[0]) + " with score of " + str(                                                            discarded_best_l_candidate[2]) + " and " + str(                                                            discarded_best_r_candidate[0]) + " with score of " + str(                                                            discarded_best_r_candidate[2]))                        # ipdb.set_trace()                        discard_tally += 1                        if not discard_record.seq:                            empty_tally += 1                        else:                            # ipdb.set_trace()                            SeqIO.write(discard_record, b, "fasta")                            SeqIO.write(discard_record, bb, "fasta")                            SeqIO.write(discard_record_full, c, "fasta")                            SeqIO.write(discard_record_full, cc, "fasta")                            # discard_records += [discard_record]                            if counter % 1000 == 0:                                # iteration_end_t = time.time()                                # iteration_time = iteration_end_t - iteration_start_t                                # average_iteration_time = (average_iteration_time * counter - 1 + iteration_time) / counter                                print 'reads processed so far: '+ str(counter)                                # print average_iteration_time                                # process = psutil.Process(os.getpid())                                # print(process.memory_info().rss)                    else:                        accepted_cs_position += [flipped_read[3]+11]                        # ipdb.set_trace()                        pairwise_association_matrix[left_placeholder,right_placeholder] += 1                        umireduced_pairwise_association_matrix[left_placeholder,right_placeholder] += 1.0/inverse_weight                        pairwise_association_matrix_master[left_placeholder, right_placeholder] += 1                        umireduced_pairwise_association_matrix_master[left_placeholder, right_placeholder] += 1.0/inverse_weight                        pair_record = SeqRecord(Seq(flipped_read[1][flipped_read[3]-6:flipped_read[4]+6]),                                                   id='PAIR_'+str(left_placeholder)+ '_'+str(right_placeholder)+'_ID'+seq_record.id,                                                   name='PAIR_'+str(left_placeholder)+ '_'+str(right_placeholder)+'_ID'+seq_record.id,                                                   description="accepted candidates discovered: " + str(                                                       left_sequences[left_placeholder]) + " with score of " + str(                                                       bc_1_extract[2]) +" and " + str(right_sequences[right_placeholder])                                                +" with score of " + str(                                                       bc_2_extract[2]))                        pair_record_full = SeqRecord(main_sequence,                                                id='PAIR_' + str(left_placeholder) + '_' + str(                                                    right_placeholder) + '_ID' + seq_record.id,                                                name='PAIR_' + str(left_placeholder) + '_' + str(                                                    right_placeholder) + '_ID' + seq_record.id,                                                description="accepted candidates discovered: " + str(                                                    left_sequences[left_placeholder]) + " with score of " + str(                                                    bc_1_extract[2]) + " and " + str(right_sequences[right_placeholder])                                                            + " with score of " + str(                                                    bc_2_extract[2]))                        good_tally += 1                        if not pair_record.seq:                            empty_tally += 1                        else:                            SeqIO.write(pair_record, a, "fasta")                            SeqIO.write(pair_record, aa, "fasta")                            SeqIO.write(pair_record_full, d, "fasta")                            SeqIO.write(pair_record_full, dd, "fasta")                            # pair_records += [pair_record]                            if counter%1000 == 0:                                # iteration_end_t = time.time()                                # iteration_time = iteration_end_t - iteration_start_t                                # average_iteration_time = (average_iteration_time * counter - 1 + iteration_time) / counter                                print 'reads processed so far: '+ str(counter)                                # print average_iteration_time                                # process = psutil.Process(os.getpid())                                # print(process.memory_info().rss)        bins = range(0,len(main_sequence),2)        # plt.hist(common_sequence_positions, bins=bins,alpha=0.4,ls='--',color='k')        plt.hist(accepted_cs_position, bins=bins,alpha=0.8,color='c')        plt.hist(discarded_cs_position, bins=bins,alpha=0.8,color='r')        plt.savefig(directory_name + '/position_hist.svg')        plt.savefig(directory_name + '/position_hist.png')        # with open(directory_name + "/raw.fsa", "w") as output_handle:        #     SeqIO.write(pair_records, output_handle, "fasta")        percentsuccess = float(good_tally) / float(good_tally + discard_tally)        text_file = open(directory_name + "/summary.txt", "w")        text_file.write("file name: %s" % file)        text_file.write("\nnumber of good pairings: %s" % good_tally)        text_file.write("\nnumber of discarded reads: %s" % discard_tally)        text_file.write("\ntotal reads by full tally: %s" % full_tally)        text_file.write("\ntally discarepancy: %s" % str(full_tally-discard_tally-good_tally))        text_file.write("\ncommon sequence mismatch threshold: %s" % cs_thresh)        text_file.write("\ncommon sequence mismatch threshold: %s" % common_sequence_score_threshold)        text_file.write("\nbarcode mismatch threshold: %s" % bc_thresh)        text_file.write("\nbarcode mismatch threshold: %s" % barcode_score_threshold)        text_file.write("\nbarcode pairing success rate: %s" % percentsuccess)        text_file.close()        np.savetxt(directory_name + '/association_matrix', pairwise_association_matrix)        plt.imshow(pairwise_association_matrix, cmap='Blues',interpolation='none')        plt.yticks(np.arange(len(left_sequences)), left_sequences)        plt.xticks(np.arange(len(right_sequences)), right_sequences)        plt.savefig(directory_name + '/accepted_matrix.svg')        plt.savefig(directory_name + '/accepted_matrix.png')        plt.close()        np.savetxt(directory_name + '/umireduced_as_matrix', umireduced_pairwise_association_matrix)        plt.imshow(umireduced_pairwise_association_matrix, cmap='Blues',interpolation='none')        plt.yticks(np.arange(len(left_sequences)), left_sequences)        plt.xticks(np.arange(len(right_sequences)), right_sequences)        plt.savefig(directory_name + '/umiaccepted_matrix.svg')        plt.savefig(directory_name + '/umiaccepted_matrix.png')        plt.close()        np.savetxt(directory_name + '/discard_matrix', discard_association_matrix)        plt.imshow(discard_association_matrix, cmap='Blues',interpolation='none')        plt.yticks(np.arange(len(left_sequences)), left_sequences)        plt.xticks(np.arange(len(right_sequences)), right_sequences)        plt.savefig(directory_name + '/discard_matrix.svg')        plt.savefig(directory_name + '/discard_matrix.png')        plt.close()        f = open(directory_name + "/summary.txt", "r")        print '\n\n\n SUMMARY:'+f.read()        if perform_alignment == 'y':            print 'data generation complete. proceeding with multiple sequence alignments - ok to interrupt '            in_file = directory_name + "/bc_pairs.fsa"            out_file_muscle = directory_name + "/MSA_successful_pairs.fsa"            muscle_exe = "muscle3.8.31_i86win32.exe"            muscle_cline = MuscleCommandline(muscle_exe, input=in_file, out=out_file_muscle)            try:                stdout, stderr = muscle_cline(in_file)                print 'muscle alignment successful'            except:                print 'muscle alignment failed'                pass            in_file = directory_name + "/discarded.fsa"            out_file_muscle = directory_name + "/MSA_discard_records.fsa"            muscle_exe = "muscle3.8.31_i86win32.exe"            muscle_cline = MuscleCommandline(muscle_exe, input=in_file, out=out_file_muscle)            try:                stdout, stderr = muscle_cline(in_file)                print 'muscle alignment successful'            except:                print 'muscle alignment failed'                pass            in_file = directory_name + "/full_discarded.fsa"            out_file_muscle = directory_name + "/MSA_full_discarded.fsa"            muscle_exe = "muscle3.8.31_i86win32.exe"            muscle_cline = MuscleCommandline(muscle_exe, input=in_file, out=out_file_muscle)            try:                stdout, stderr = muscle_cline(in_file)                print 'muscle alignment successful'            except:                print 'muscle alignment failed'                pass            in_file = directory_name + "/full_accepted.fsa"            out_file_muscle = directory_name + "/MSA_full_accepted.fsa"            muscle_exe = "muscle3.8.31_i86win32.exe"            muscle_cline = MuscleCommandline(muscle_exe, input=in_file, out=out_file_muscle)            try:                stdout, stderr = muscle_cline(in_file)                print 'muscle alignment successful'            except:                print 'muscle alignment failed'                passnp.savetxt(super_directory + '/association_matrix_master', pairwise_association_matrix_master)plt.imshow(pairwise_association_matrix_master, cmap='Blues',interpolation='none')plt.yticks(np.arange(len(left_sequences)), left_sequences)plt.xticks(np.arange(len(right_sequences)), right_sequences)plt.savefig(super_directory + '/accepted_matrix_master.svg')plt.savefig(super_directory + '/accepted_matrix_master.png')plt.close()np.savetxt(super_directory + '/umireduced_as_matrix_master', umireduced_pairwise_association_matrix_master)plt.imshow(umireduced_pairwise_association_matrix_master, cmap='Blues',interpolation='none')plt.yticks(np.arange(len(left_sequences)), left_sequences)plt.xticks(np.arange(len(right_sequences)), right_sequences)plt.savefig(super_directory + '/umiaccepted_matrix_master.svg')plt.savefig(super_directory + '/umiaccepted_matrix_master.png')plt.close()np.savetxt(super_directory + '/discard_matrix_master', discard_association_matrix_master)plt.imshow(discard_association_matrix_master, cmap='Blues',interpolation='none')plt.yticks(np.arange(len(left_sequences)), left_sequences)plt.xticks(np.arange(len(right_sequences)), right_sequences)plt.savefig(super_directory + '/discard_matrix_master.svg')plt.savefig(super_directory + '/discard_matrix_master.png')plt.close()